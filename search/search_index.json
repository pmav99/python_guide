{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Suggestions for Python Development on Linux \u00b6 tl;dr \u00b6 The suggested setup is: Linux setup the environment in a reproducible way (e.g. using docker , ansible , conda , etc) Use a modern python version (3.6+) Create a virtualenv manage the python dependencies with poetry [Ooptional] install python cli applications using pipx Disclaimer \u00b6 First of all, a couple of definitions: A library is a provider of an API, i.e. code that gets imported by other libraries or applications An application is a consumer of APIs, i.e. code that imports other libraries The suggestions in this document are written from the point of view of the application developer. The requirements for library developers are different (more complex). Note: Obviously, the distinction made here is quite high level. You can have code that is both a library and an application, you can have a library where only part of the APi is public while the rest of the code is not meant to be imported, etc The reason we make this distinction is that in an application you only care for your code to be running with a specific python version. On the other hand, in a library you must e.g. avoid pinning your requirements to specific versions, test with multiple python versions etc.","title":"Home"},{"location":"#suggestions-for-python-development-on-linux","text":"","title":"Suggestions for Python Development on Linux"},{"location":"#tldr","text":"The suggested setup is: Linux setup the environment in a reproducible way (e.g. using docker , ansible , conda , etc) Use a modern python version (3.6+) Create a virtualenv manage the python dependencies with poetry [Ooptional] install python cli applications using pipx","title":"tl;dr"},{"location":"#disclaimer","text":"First of all, a couple of definitions: A library is a provider of an API, i.e. code that gets imported by other libraries or applications An application is a consumer of APIs, i.e. code that imports other libraries The suggestions in this document are written from the point of view of the application developer. The requirements for library developers are different (more complex). Note: Obviously, the distinction made here is quite high level. You can have code that is both a library and an application, you can have a library where only part of the APi is public while the rest of the code is not meant to be imported, etc The reason we make this distinction is that in an application you only care for your code to be running with a specific python version. On the other hand, in a library you must e.g. avoid pinning your requirements to specific versions, test with multiple python versions etc.","title":"Disclaimer"},{"location":"01_why_linux/","text":"The choice of the operating system is for sure a controversial topic. Among other things it is a question of aeshetics, specific needs and it often boils down just to personal preference. Nevertheless, I am arguing that when it comes to Python there usually is enough justification to choose Linux over other OSes. Note For sure, any modern operating system can server your needs. The question what is the best way to serve your (programming) needs. Tip In this guide I am only describing what works for me. You should choose the OS that is serving your needs in the best possible way. dev vs prod \u00b6 An important distinction is between: the development environment (i.e. where you write the code) the production environment (i.e. where you run the code) In order to make debugging easier, you should strive to make the development environment as similar as possible to the production environment. Why Linux? \u00b6 As far as I am concerned, I consider myself I professional. When it comes to my work I want to be using the best tools I can, no questions asked. Just to give you a few examples: There is a great deal of unix tools that make development so much easier and which are not available on Windows. Some of them are available on Mac OS, but not all; see the next point. Not having native docker is a huge deal breaker for me. It is not that it doesn't work on other operating systems, but as soon as you move on from simple cases you will eventually encounter a bug or some incompatibility and you will have to start jumping through hoops. Practically speaking, in science and web-development, the vast majority of the code that you will write will be executed on Linux (HPC, HTC, super-computers, web servers etc). Remember what we said about minimizing the differences between dev and prod ? There is some truth in (big) numbers. 1 in 4 developers use Linux (regardless of Programming Language). When it comes to developers that identify themselves as primarily Python devs, 70% of them use Linux at some capacity (main OS or cnotainers). Note Is the Linux world a fairy-tale? Nope! E.g. when it comes to multimedia it is a living hell . But here we are talking about development. Not about watching movies, using bluetooth devices etc. Why not Mac? \u00b6 It is unix based. It is very polished when it comes to integration with the native applications. Many devs like Mac OS. Nevertheless, it is like Linux. It is not Linux. Note I spend most of my working time in front of a console and linux is better at that. Why not windows? \u00b6 In the past, Python on Widows was really a second class citizen. Nowadays, with platforms like conda the situation is for sure better, nevertheless there are still restrictions. For example: Eventually you will need something that is not available via a pre-compiled package and compiling C-Extentions on Windows is a major PITA. Dealing with multi-processing and multi-threading on windows is not what you call fun. There are a lot of subtle details that are different than Linux and usually that's where you will run your code. How about VMs and WSL? \u00b6 There are two more options: Using Windows or Mac as the host operating system and using Linux in a Virtual Machine (VM) Using Windows Subsystem for Linux (WSL) For a short period, I did use a VM and someone whose opinion I value uses it extensively . In the past (2000s) when computers were much weaker it was not really a viable choice. Nowadays, it works just fine though. Personally I haven't used WSL. I know that it is being actively developed/improved. It is for sure a technology worth keeping our eyes upon. As of today, between the two, I think I would choose a VM.","title":"Why Linux?"},{"location":"01_why_linux/#dev-vs-prod","text":"An important distinction is between: the development environment (i.e. where you write the code) the production environment (i.e. where you run the code) In order to make debugging easier, you should strive to make the development environment as similar as possible to the production environment.","title":"dev vs prod"},{"location":"01_why_linux/#why-linux","text":"As far as I am concerned, I consider myself I professional. When it comes to my work I want to be using the best tools I can, no questions asked. Just to give you a few examples: There is a great deal of unix tools that make development so much easier and which are not available on Windows. Some of them are available on Mac OS, but not all; see the next point. Not having native docker is a huge deal breaker for me. It is not that it doesn't work on other operating systems, but as soon as you move on from simple cases you will eventually encounter a bug or some incompatibility and you will have to start jumping through hoops. Practically speaking, in science and web-development, the vast majority of the code that you will write will be executed on Linux (HPC, HTC, super-computers, web servers etc). Remember what we said about minimizing the differences between dev and prod ? There is some truth in (big) numbers. 1 in 4 developers use Linux (regardless of Programming Language). When it comes to developers that identify themselves as primarily Python devs, 70% of them use Linux at some capacity (main OS or cnotainers). Note Is the Linux world a fairy-tale? Nope! E.g. when it comes to multimedia it is a living hell . But here we are talking about development. Not about watching movies, using bluetooth devices etc.","title":"Why Linux?"},{"location":"01_why_linux/#why-not-mac","text":"It is unix based. It is very polished when it comes to integration with the native applications. Many devs like Mac OS. Nevertheless, it is like Linux. It is not Linux. Note I spend most of my working time in front of a console and linux is better at that.","title":"Why not Mac?"},{"location":"01_why_linux/#why-not-windows","text":"In the past, Python on Widows was really a second class citizen. Nowadays, with platforms like conda the situation is for sure better, nevertheless there are still restrictions. For example: Eventually you will need something that is not available via a pre-compiled package and compiling C-Extentions on Windows is a major PITA. Dealing with multi-processing and multi-threading on windows is not what you call fun. There are a lot of subtle details that are different than Linux and usually that's where you will run your code.","title":"Why not windows?"},{"location":"01_why_linux/#how-about-vms-and-wsl","text":"There are two more options: Using Windows or Mac as the host operating system and using Linux in a Virtual Machine (VM) Using Windows Subsystem for Linux (WSL) For a short period, I did use a VM and someone whose opinion I value uses it extensively . In the past (2000s) when computers were much weaker it was not really a viable choice. Nowadays, it works just fine though. Personally I haven't used WSL. I know that it is being actively developed/improved. It is for sure a technology worth keeping our eyes upon. As of today, between the two, I think I would choose a VM.","title":"How about VMs and WSL?"},{"location":"02_reproducible_environment/","text":"Reproducible environments \u00b6 What is an environment? \u00b6 In the context we are discussing, setting up the environment means to make sure that all the non-python programs and libraries that your application needs are available. For example: your code is calling a 3rd party program using subprocess . one of your python dependencies is a \" C-extension \" and there is no wheel for it. This means that in order to install it you must compile it. In a nutshell, both gcc and the python headers must be available (you install the latter by installing the python-dev package on debian/ubuntu). Setting up the environment means to make sure that whatever is required in order to start developing is available. Reproducible environments \u00b6 A crucial detail is that the environment should be reproducible . This is something that affects both the development environment and the production environment Reproducible dev-environments mean that in case: your laptop breaks down, you can easily continue your work on a different one a new developer joins the team, he can start doing actual work without too much trouble you stop working on the project, you can easily hand-over to someone else. Reproducible prod-environments are essential for keeping your sanity... Setting up a reproducible environment \u00b6 To what extends you will go to create reproducible environments depends, among other things, on: the complexity of the project the importance of the project the number of devs that work on it Tip For \"run-once-and-throw-away\" scripts you obviously do nothing. For really simple projects and projects that only you work on, it is usually enough to just document any special needs in the readme. I.e. it usually not worth it to setup an automatic way to reproduce the environment. For more complex stuff though, there are multiple ways with which you can handle the \"reproducibility\" of the environment. I will not cover them in detail here, but reasonable choices are: docker which is probably the most flexible, but it also has a relatively steep learning curve. Nevertheless, learning at least the basics is really worth it. ansible which is useful when you work with VPS. conda which, especially among scientists, is a popular choice but it IMHV has several shortcomings . Among other things, often is not even an option for running things on production (e.g. if you run your code on a HPC/HTC cluster conda might be forbidden as it can be a security nightmare for the sys-admins). Note: In production, you often use a combination of the above. E.g. you create a VPS, you use ansible or terraform in order to set it up, \"harden\" it and install plain docker or kubernetes which is what you actually use to run your code.","title":"Reproducible environments"},{"location":"02_reproducible_environment/#reproducible-environments","text":"","title":"Reproducible environments"},{"location":"02_reproducible_environment/#what-is-an-environment","text":"In the context we are discussing, setting up the environment means to make sure that all the non-python programs and libraries that your application needs are available. For example: your code is calling a 3rd party program using subprocess . one of your python dependencies is a \" C-extension \" and there is no wheel for it. This means that in order to install it you must compile it. In a nutshell, both gcc and the python headers must be available (you install the latter by installing the python-dev package on debian/ubuntu). Setting up the environment means to make sure that whatever is required in order to start developing is available.","title":"What is an environment?"},{"location":"02_reproducible_environment/#reproducible-environments_1","text":"A crucial detail is that the environment should be reproducible . This is something that affects both the development environment and the production environment Reproducible dev-environments mean that in case: your laptop breaks down, you can easily continue your work on a different one a new developer joins the team, he can start doing actual work without too much trouble you stop working on the project, you can easily hand-over to someone else. Reproducible prod-environments are essential for keeping your sanity...","title":"Reproducible environments"},{"location":"02_reproducible_environment/#setting-up-a-reproducible-environment","text":"To what extends you will go to create reproducible environments depends, among other things, on: the complexity of the project the importance of the project the number of devs that work on it Tip For \"run-once-and-throw-away\" scripts you obviously do nothing. For really simple projects and projects that only you work on, it is usually enough to just document any special needs in the readme. I.e. it usually not worth it to setup an automatic way to reproduce the environment. For more complex stuff though, there are multiple ways with which you can handle the \"reproducibility\" of the environment. I will not cover them in detail here, but reasonable choices are: docker which is probably the most flexible, but it also has a relatively steep learning curve. Nevertheless, learning at least the basics is really worth it. ansible which is useful when you work with VPS. conda which, especially among scientists, is a popular choice but it IMHV has several shortcomings . Among other things, often is not even an option for running things on production (e.g. if you run your code on a HPC/HTC cluster conda might be forbidden as it can be a security nightmare for the sys-admins). Note: In production, you often use a combination of the above. E.g. you create a VPS, you use ansible or terraform in order to set it up, \"harden\" it and install plain docker or kubernetes which is what you actually use to run your code.","title":"Setting up a reproducible environment"},{"location":"03_python_versions/","text":"Python Versions \u00b6 Which version of Python should I use? \u00b6 As of today (June 2020), if you start a new project , you should be using Python 3.8.2+ Python 3.7.2+ is OK too. Versions below 3.6 should be avoided since they lack support for numerous, backward incompatible, language features including: f-strings type annotations async support dataclasses When should I upgrade my Python version? \u00b6 When developing an application, upgrading the python version is not something that you are required to do. Often, it is perfectly fine to continue using an older version, especially, for applications that are not being actively developed. That being said though, if you continue to develop your application sticking to the older versions comes with certain drawbacks: you are potentially missing security enhancements you are missing new language features the more you postpone upgrading (e.g. if you skip a version or two) the more difficult is going to be to make the upgrade eventually. Upgrading python versions is something that you can schedule to do every 18-24 months and, to the extent that you have a comprehensive test suite, it can be a relatively painless experience. Using new python releases (i.e. X.Y.0 and X.Y.1 ) should be avoided since you may encounter various problems (e.g. missing wheel packages etc). So, wait until at least X.Y.2 comes out.","title":"Which Python version?"},{"location":"03_python_versions/#python-versions","text":"","title":"Python Versions"},{"location":"03_python_versions/#which-version-of-python-should-i-use","text":"As of today (June 2020), if you start a new project , you should be using Python 3.8.2+ Python 3.7.2+ is OK too. Versions below 3.6 should be avoided since they lack support for numerous, backward incompatible, language features including: f-strings type annotations async support dataclasses","title":"Which version of Python should I use?"},{"location":"03_python_versions/#when-should-i-upgrade-my-python-version","text":"When developing an application, upgrading the python version is not something that you are required to do. Often, it is perfectly fine to continue using an older version, especially, for applications that are not being actively developed. That being said though, if you continue to develop your application sticking to the older versions comes with certain drawbacks: you are potentially missing security enhancements you are missing new language features the more you postpone upgrading (e.g. if you skip a version or two) the more difficult is going to be to make the upgrade eventually. Upgrading python versions is something that you can schedule to do every 18-24 months and, to the extent that you have a comprehensive test suite, it can be a relatively painless experience. Using new python releases (i.e. X.Y.0 and X.Y.1 ) should be avoided since you may encounter various problems (e.g. missing wheel packages etc). So, wait until at least X.Y.2 comes out.","title":"When should I upgrade my Python version?"},{"location":"04_developing_python_applications/","text":"Developing python applications \u00b6","title":"Developing Python Applications"},{"location":"04_developing_python_applications/#developing-python-applications","text":"","title":"Developing python applications"},{"location":"05_installing_python_applications/","text":"Installing Python applications ? \u00b6 While developing you will very often need to make use of some python CLI application. Nevertheless, often these applications are not packaged for your distribution and/or if you use a server distro or an LTS distro, the packages might be ancient. Prime examples of such applications are: ansible docker-compose pgcli poetry invoke httpie There are multiple ways that you can install such applications. For good or for bad, not all of them are equal. What not to do? \u00b6 Unfortunately, some quite popular suggestion from the internet should be avoided : sudo pip install pip install --user apt install , yum install or any other distribution pacakge manager What is the problem with sudo pip install \u00b6 You should NEVER use sudo pip install . Unless you want to end up with a broken linux installation, that is. The problems is that by using sudo pip install you may override/replace files that were previously installed by apt . Moreover, you might upgrade some packages to versions that are not compatible with other packages that are currently installed. And don't forget that the Python is being used by the linux distribution itself. So whenever you run sudo pip install you run the risk of breaking your Linux distribution in ways that might not be apparent and which might bite you even years later! And the worst is that you will break something and you will have zero warning that you did break it. For example if you try to upgrade ubuntu 18.04 to 20.04 the upgrade might fail because the files you have under /usr are no longer managed by apt , because you updated a package with sudo pip install Recovering the system from sudo pip install is possible but it is not fun and you must know what you are doing. What is the problem with pip install --user \u00b6 pip install --user installs packages in ~/.local/lib/pythonX.Y/site-packages The problem is that pip does not do dependency resolution (in the future this is planned to change ). It just installs packages. For example: package A requires package K Version <2.0 package B requires package K Version >2.0 If you do pip install --user A you will also install K version 1.X. If you follow this command with pip install --user B , then K will be upgraded to version 2.X and A will be broken without any warnings . So, by using pip install --user you solve a short term problem but you might introduce other problems in the future that might be hard to debug. And anyhow, since there are way cleaner options, why use something suboptimal? How about installing stuff with my distro's package manager (e.g. apt or yum )? \u00b6 The package manager can work just fine as long as you stick it. There are some downsides though: not everything is available packages are often outdated most often than not you are forced to use a specific version As an application developper, I want to have the freedom to solve the problem I am facing in the best way possible. Fighting with old APIs is not helping in that direction. How about creating a virtualenv and installing the application there? \u00b6 This is by far the best option. You achieve complete isolation of the application both from other applications and from the system. Nevertheless, it is cumbersome: You need to create the virtual environment manually install the package manually create symlinks to ~/.local/bin manually you need to remember to remove the symlinks when you remove the application. Thankfully, there is a tool that automates the virtualenv procedure. It is called pipx . pipx ? \u00b6 pipx is a package that lets you Install and Run Python Applications in Isolated Environments. Installation \u00b6 pipx only has two requirements: Python 3.6+ ~/.local/bin must be in your $PATH To install it you should use: python3 -mpip install --user pipx yes, earlier, we suggested not to use pip install --user , but we will only be installing this very package with pip install --user . All the others will be installed by pipx itself. Usage \u00b6 Using pipx is pretty simple. you just run pipx install <package-name> where <package-name> is the name of any PyPi package. Behind the scenes, pipx will: Create a dedicated Virtual Environemnt in ~/.local/pipx/virtualenvs Install the application in the virtualenv Create a symlink from ~/.local/pipx/virtualenvs/<package_name>/bin/<executable> to ~/.local/bin To uninstall a package you just: pipx uninstall <package_name> and this will remove both the virtualenv and the symlink","title":"Installing Python Applications"},{"location":"05_installing_python_applications/#installing-python-applications","text":"While developing you will very often need to make use of some python CLI application. Nevertheless, often these applications are not packaged for your distribution and/or if you use a server distro or an LTS distro, the packages might be ancient. Prime examples of such applications are: ansible docker-compose pgcli poetry invoke httpie There are multiple ways that you can install such applications. For good or for bad, not all of them are equal.","title":"Installing Python applications?"},{"location":"05_installing_python_applications/#what-not-to-do","text":"Unfortunately, some quite popular suggestion from the internet should be avoided : sudo pip install pip install --user apt install , yum install or any other distribution pacakge manager","title":"What not to do?"},{"location":"05_installing_python_applications/#what-is-the-problem-with-sudo-pip-install","text":"You should NEVER use sudo pip install . Unless you want to end up with a broken linux installation, that is. The problems is that by using sudo pip install you may override/replace files that were previously installed by apt . Moreover, you might upgrade some packages to versions that are not compatible with other packages that are currently installed. And don't forget that the Python is being used by the linux distribution itself. So whenever you run sudo pip install you run the risk of breaking your Linux distribution in ways that might not be apparent and which might bite you even years later! And the worst is that you will break something and you will have zero warning that you did break it. For example if you try to upgrade ubuntu 18.04 to 20.04 the upgrade might fail because the files you have under /usr are no longer managed by apt , because you updated a package with sudo pip install Recovering the system from sudo pip install is possible but it is not fun and you must know what you are doing.","title":"What is the problem with sudo pip install"},{"location":"05_installing_python_applications/#what-is-the-problem-with-pip-install-user","text":"pip install --user installs packages in ~/.local/lib/pythonX.Y/site-packages The problem is that pip does not do dependency resolution (in the future this is planned to change ). It just installs packages. For example: package A requires package K Version <2.0 package B requires package K Version >2.0 If you do pip install --user A you will also install K version 1.X. If you follow this command with pip install --user B , then K will be upgraded to version 2.X and A will be broken without any warnings . So, by using pip install --user you solve a short term problem but you might introduce other problems in the future that might be hard to debug. And anyhow, since there are way cleaner options, why use something suboptimal?","title":"What is the problem with pip install --user"},{"location":"05_installing_python_applications/#how-about-installing-stuff-with-my-distros-package-manager-eg-apt-or-yum","text":"The package manager can work just fine as long as you stick it. There are some downsides though: not everything is available packages are often outdated most often than not you are forced to use a specific version As an application developper, I want to have the freedom to solve the problem I am facing in the best way possible. Fighting with old APIs is not helping in that direction.","title":"How about installing stuff with my distro's package manager (e.g. apt or yum)?"},{"location":"05_installing_python_applications/#how-about-creating-a-virtualenv-and-installing-the-application-there","text":"This is by far the best option. You achieve complete isolation of the application both from other applications and from the system. Nevertheless, it is cumbersome: You need to create the virtual environment manually install the package manually create symlinks to ~/.local/bin manually you need to remember to remove the symlinks when you remove the application. Thankfully, there is a tool that automates the virtualenv procedure. It is called pipx .","title":"How about creating a virtualenv and installing the application there?"},{"location":"05_installing_python_applications/#pipx","text":"pipx is a package that lets you Install and Run Python Applications in Isolated Environments.","title":"pipx?"},{"location":"05_installing_python_applications/#installation","text":"pipx only has two requirements: Python 3.6+ ~/.local/bin must be in your $PATH To install it you should use: python3 -mpip install --user pipx yes, earlier, we suggested not to use pip install --user , but we will only be installing this very package with pip install --user . All the others will be installed by pipx itself.","title":"Installation"},{"location":"05_installing_python_applications/#usage","text":"Using pipx is pretty simple. you just run pipx install <package-name> where <package-name> is the name of any PyPi package. Behind the scenes, pipx will: Create a dedicated Virtual Environemnt in ~/.local/pipx/virtualenvs Install the application in the virtualenv Create a symlink from ~/.local/pipx/virtualenvs/<package_name>/bin/<executable> to ~/.local/bin To uninstall a package you just: pipx uninstall <package_name> and this will remove both the virtualenv and the symlink","title":"Usage"},{"location":"app_conda/","text":"What conda really is \u00b6 Half the posts you will find online compare conda to pip . IMHV this is really unfortunate. conda is not really comparable to pip . pip only deals with python packages that are available through a Python Package Index . conda on the other hand, is a generic package manager . A more likely comparison is to compare it with apt or yum . conda can install compiled binaries . E.g. you can use conda to install gcc , or openssh-client With conda you can create a parallel installation of the OS (not of the kernel, but of the userspace). It practically allows you to have parallel \"branches\" where you can install different versions of programs and libraries, and it gives you an easy way to switch between them. Tip This is a similar concept to python's virtualenvs but conda has a much bigger scope. So you can have one branch/environment where you install for example GDAL version 2 and another where you install GDAL version 3. Creating a similar setup without conda , is doable of course, but before docker became a thing, it was a pain. Warning Security-wise this is a nightmare though. conda gives you a really easy way to bypass root permissions... Why not conda \u00b6 Personally, since I almost exclusively deal with Linux, I don't find much benefit in conda . it is notoriously slow, it takes a huge amount of space, downloading random binaries from the internet is rather iffy from a security point of view, conda binaries are usually compiled with generic options so performance can be sub-optimal, etc, etc. All in all, IMHV docker + apt + pip is more than an adequate alternative, and I would even say, a superior alternative. Note Of course docker has a learning curve, and I am talking here from the point of view of someone who has already paid the price, so you could say that I am biased... When conda really shines? \u00b6 IMHV conda makes a lot of sense on OSes that make it really difficult to compile things from source (i.e. Windows). In these environments installing a Python C-Extension to can be a real PITA. It also makes some sense on e.g. Mac OS if you want to avoid using homebrew etc. Installing binaries is easier after all. On Linux though you don't really have such problems. Even if you need to compile something, it is usually relatively easy to do so (or at the very least, easier than the other OSes). How can you use conda on linux? \u00b6 If you decide to use conda you should use it to setup your environment . For a more detailed explanation of what this entails, please check the relevant section . In a nutshell, in the context we are discussing, it means to make sure that all the packages and libraries that you application needs are available. To make this clear, it might make sense to include in the discussion pip . pip is a package manager. Nevertheless, it only deals with Python packages. You can't install non-python stuff with pip . So for example you can't install gcc or gdalinfo with pip . You can only install the python bindings for GDAL , not GDAL proper. So, if your code is calling another program using e.g. subprocess , it is your job to make sure that the program is there. pip can't help you with that. That's where conda comes in. So you should use conda to: create your environment , install the non-python dependencies there (e.g. python=3.7.3 , gdal=3.0.4 etc). These dependencies should be pinned in your environment.yaml . and then create a virtualenv using the python you installed via conda and manage your python dependencies using poetry . These dependencies should be pined in your pyproject.toml/poetry.lock This way, you can continue to use the standard python ecosystem and have consistency across different environments and OSes. Tip If you do decide to use conda though, my suggestion is to use conda all the way. So if you need e.g. GDAL and openssl install both from conda , not one with conda and the other with apt . Warning REMEMBER: don't mix up packages from different package managers in your environment. This can only lead to trouble.","title":"conda"},{"location":"app_conda/#what-conda-really-is","text":"Half the posts you will find online compare conda to pip . IMHV this is really unfortunate. conda is not really comparable to pip . pip only deals with python packages that are available through a Python Package Index . conda on the other hand, is a generic package manager . A more likely comparison is to compare it with apt or yum . conda can install compiled binaries . E.g. you can use conda to install gcc , or openssh-client With conda you can create a parallel installation of the OS (not of the kernel, but of the userspace). It practically allows you to have parallel \"branches\" where you can install different versions of programs and libraries, and it gives you an easy way to switch between them. Tip This is a similar concept to python's virtualenvs but conda has a much bigger scope. So you can have one branch/environment where you install for example GDAL version 2 and another where you install GDAL version 3. Creating a similar setup without conda , is doable of course, but before docker became a thing, it was a pain. Warning Security-wise this is a nightmare though. conda gives you a really easy way to bypass root permissions...","title":"What conda really is"},{"location":"app_conda/#why-not-conda","text":"Personally, since I almost exclusively deal with Linux, I don't find much benefit in conda . it is notoriously slow, it takes a huge amount of space, downloading random binaries from the internet is rather iffy from a security point of view, conda binaries are usually compiled with generic options so performance can be sub-optimal, etc, etc. All in all, IMHV docker + apt + pip is more than an adequate alternative, and I would even say, a superior alternative. Note Of course docker has a learning curve, and I am talking here from the point of view of someone who has already paid the price, so you could say that I am biased...","title":"Why not conda"},{"location":"app_conda/#when-conda-really-shines","text":"IMHV conda makes a lot of sense on OSes that make it really difficult to compile things from source (i.e. Windows). In these environments installing a Python C-Extension to can be a real PITA. It also makes some sense on e.g. Mac OS if you want to avoid using homebrew etc. Installing binaries is easier after all. On Linux though you don't really have such problems. Even if you need to compile something, it is usually relatively easy to do so (or at the very least, easier than the other OSes).","title":"When conda really shines?"},{"location":"app_conda/#how-can-you-use-conda-on-linux","text":"If you decide to use conda you should use it to setup your environment . For a more detailed explanation of what this entails, please check the relevant section . In a nutshell, in the context we are discussing, it means to make sure that all the packages and libraries that you application needs are available. To make this clear, it might make sense to include in the discussion pip . pip is a package manager. Nevertheless, it only deals with Python packages. You can't install non-python stuff with pip . So for example you can't install gcc or gdalinfo with pip . You can only install the python bindings for GDAL , not GDAL proper. So, if your code is calling another program using e.g. subprocess , it is your job to make sure that the program is there. pip can't help you with that. That's where conda comes in. So you should use conda to: create your environment , install the non-python dependencies there (e.g. python=3.7.3 , gdal=3.0.4 etc). These dependencies should be pinned in your environment.yaml . and then create a virtualenv using the python you installed via conda and manage your python dependencies using poetry . These dependencies should be pined in your pyproject.toml/poetry.lock This way, you can continue to use the standard python ecosystem and have consistency across different environments and OSes. Tip If you do decide to use conda though, my suggestion is to use conda all the way. So if you need e.g. GDAL and openssl install both from conda , not one with conda and the other with apt . Warning REMEMBER: don't mix up packages from different package managers in your environment. This can only lead to trouble.","title":"How can you use conda on linux?"}]}